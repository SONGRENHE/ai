{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression - Interpretation of Coefficients\n",
    "\n",
    "This notebooks aims to provide some clarification and more insights into interpreting Linear Regression Models and the effect of data normalization on this task. We talked about the main take-away messages in the lecture, but it becomes arguably much clearer and more convincing with some hands-on example.\n",
    "\n",
    "Let's get started...\n",
    "\n",
    "\n",
    "## Setting up the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "To make the use case interesting, I aligned it with the Kaggle InClass competition for predicting the resale prices of HDB flats. I used the original data but made a series of changes to keep it simple for the context of this notebook:\n",
    "\n",
    "* Removed a whole bunch of attributes/features from the dataset\n",
    "\n",
    "* Considered only 1 month of transactions\n",
    "\n",
    "* Considered only transactions with `flat_type` being \"x rooms\" (e.g., I excluded \"executive\"); this allows to generate a new column `num_rooms` which is now numerical\n",
    "\n",
    "* Converted `storey_range` to `floor` by converting, e.g., \"07 TO 09\" to 8, making it a numerical feature as well\n",
    "\n",
    "* Converted the area from square meters to square feet simply to increase the magnitude of the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_rooms</th>\n",
       "      <th>floor</th>\n",
       "      <th>area_sqft</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>785.8</td>\n",
       "      <td>238500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>753.5</td>\n",
       "      <td>423000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>785.8</td>\n",
       "      <td>207000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>785.8</td>\n",
       "      <td>252000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>731.9</td>\n",
       "      <td>198000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_rooms  floor  area_sqft     price\n",
       "0          3      5      785.8  238500.0\n",
       "1          3     20      753.5  423000.0\n",
       "2          3      2      785.8  207000.0\n",
       "3          3      5      785.8  252000.0\n",
       "4          3      8      731.9  198000.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/hdb-resale-prizes-demo.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the dataframe into numpy arrays to be fed into the Linear Regression implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset contains 1780 samples with 3 features\n"
     ]
    }
   ],
   "source": [
    "X = df[['num_rooms', 'floor', 'area_sqft']].to_numpy()\n",
    "y = df['price'].to_numpy()\n",
    "\n",
    "num_samples, num_features = X.shape\n",
    "\n",
    "print('The dataset contains {} samples with {} features'.format(num_samples, num_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Linear Regression Models\n",
    "\n",
    "\n",
    "### Without Data Normalization\n",
    "\n",
    "Let's first train a Linear Regression model without normalizing the data. As your data is already in a proper shape -- there are only basic numerical features -- we can immediately use scikit-learn's [`LinearRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) implementation. Note that we do not split the data in to training and test data, since we're not interested in the predictive power of the model but only in the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression(fit_intercept=True).fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficients\n",
    "\n",
    "The coefficients can be found in `lin_reg.coef_` and are in the same order as the features in your dataset (both `X` and `df`) which allows us to match the coefficients to the respective feature names. The code below is just doing that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing [num_rooms] by 1 unit will increase the resale price by 49836.83 SGD\n",
      "Increasing [floor] by 1 unit will increase the resale price by 7765.77 SGD\n",
      "Increasing [area_sqft] by 1 unit will increase the resale price by 152.7 SGD\n"
     ]
    }
   ],
   "source": [
    "for idx in range(num_features):\n",
    "    \n",
    "    # Get feature name as the column name from the dataframe\n",
    "    feature = df.columns[idx]\n",
    "    \n",
    "    # Get the corresponding coefficient\n",
    "    coefficient = np.around(lin_reg.coef_[idx], 2)\n",
    "    \n",
    "    # Print the information\n",
    "    print('Increasing [{}] by 1 unit will increase the resale price by {} SGD'.format(feature, coefficient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we did not normalize the data, we have preserved to original units of each feature (number of rooms, floor, area in squere feet). This allows us to make the statement that, for example, increasing the number of rooms by one will increase our estimation for the resale price about S\\\\$50k.\n",
    "\n",
    "However, we cannot say that `num_rooms` is the most important feature since the coefficients are not comparable which each other because the features have values of different magnitudes. While `num_rooms` and `floor` have single-digit or low double-digit values, `area_sqft` has values in the range of several hundreds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intercept (Offset, Bias)\n",
    "\n",
    "Apart from the coefficients, we can also look at the intercept (i.e., $\\theta_0$). This reflects the estimated prices if all features are 0. The intercept can be found in `lin_reg_intercept_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept value: -43845.0\n"
     ]
    }
   ],
   "source": [
    "print('Intercept value: {}'.format(np.around(lin_reg.intercept_), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A negative estimate resale for the resale prize is of course completely counter-intuitive. This doesn't really pose a problem as there is not flat with 0 rooms and an area of 0.0 square feet (a flat on floor 0 is realistic, though). \n",
    "\n",
    "This quick exercise was mainly to show that the model is basically only defined over the same range as the training data. While it might extrapolate well to some extent, there are obvious limits when it comes to completely unrealistic values for the different input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions\n",
    "\n",
    "We can also experiment with a range of valid inputs by making other predictions that include features values way outside the range of the training data. The following example, assumes a float on the 887th floor, with the other features values realistic. The 887 would be the top floor of the [Tower of Babel](https://en.wikipedia.org/wiki/Tower_of_Babel) (2,484m) assuming an [average floor-to-floor height of 2.8 m](https://www.hdb.gov.sg/-/media/doc/HMG/11-hdb-requirements-for-aa-work-on-hdb-premises.pdf) -- just don't takes this too serious :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated resale prices is 7108433.76 SGD\n"
     ]
    }
   ],
   "source": [
    "X_babel = [[3, 887, 750]] # Original values [[3, 887, 750]]\n",
    "\n",
    "y_babel = np.around(lin_reg.predict(X_babel), 2)\n",
    "\n",
    "print('The estimated resale prices is {} SGD'.format(y_babel.squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you only have 2 Million SGD to spare but still want to live on the top floor, you only need to find a flat with `-100` rooms (just replace `3` with `-100` as the first values). Again, this is simply to showcase that the model is only (well) define over the range of feature values covered by the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Data Normalization\n",
    "\n",
    "No we train a Linear Regression model after normalizing the data. In this case, we use standardization to normalize all features. While this bring all features in the same range, it naturally destroys the original units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(X)\n",
    "\n",
    "X_scaled = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have look at a single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.26009391 -0.61894455 -0.97408545]\n"
     ]
    }
   ],
   "source": [
    "print(X_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not only are in this case all values negative, but real values for `num_rooms` and `floor` is not meaningful as well. However, the Linear Regression doesn't care, and we can simple train a model same as above (just using the scaled data):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg_scaled = LinearRegression(fit_intercept=True).fit(X_scaled, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coefficients\n",
    "\n",
    "Again, we first look at the learned coefficients can be found in `lin_reg.coef_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient for [num_rooms]: by 38394.7\n",
      "Coefficient for [floor]: by 45781.72\n",
      "Coefficient for [area_sqft]: by 33992.9\n"
     ]
    }
   ],
   "source": [
    "for idx in range(num_features):\n",
    "    \n",
    "    # Get feature name as the column name from the dataframe\n",
    "    feature = df.columns[idx]\n",
    "    \n",
    "    # Get the corresponding coefficient\n",
    "    coefficient = np.around(lin_reg_scaled.coef_[idx], 2)\n",
    "    \n",
    "    # Print the information\n",
    "    print('Coefficient for [{}]: by {}'.format(feature, coefficient))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can no longer say that increase the number of rooms by 1 will increase the estimated resale price by around S\\\\$38. The only reason why it's even similar to S\\\\$50k (see above) is because the range of values for `num_rooms` before and after the normalization is comparable. Not the difference is much more pronounced for `area_sqft` and even `floor`.\n",
    "\n",
    "On the upside, we can now directly compare the different coefficients. Since `floor` has the largest coefficient, we can argue that `floor` is in fact the most important feature/predictor for estimating the resale price and `area_sqft` the least important one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intercept (Offset, Bias)\n",
    "\n",
    "Finally, let's check the intercept $\\theta_0$ for model fitted over the normalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept value: 374318.0\n"
     ]
    }
   ],
   "source": [
    "print('Intercept value: {}'.format(np.around(lin_reg_scaled.intercept_), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value looks now much more reasonable, and this should be a surprise. Recall that standardization centers the data by subtracting the mean from each feature value. This means that `num_rooms=0.0`, `floor=0.0` and `area_sqft=0.0` are meaning values, in fact representing the \"most average flat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Predictions\n",
    "\n",
    "Of course, we can now use this model to predict the resale price for new data samples. The only important step we have to perform is to normalize the samples the same way as we did the training data. The code below uses the same sample `X_babel` from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated resale prices is 7108433.76 SGD\n"
     ]
    }
   ],
   "source": [
    "# Normalize data sample\n",
    "X_babel_scaled = scaler.transform(X_babel)\n",
    "\n",
    "y_babel = np.around(lin_reg.predict(X_babel), 2)\n",
    "\n",
    "print('The estimated resale prices is {} SGD'.format(y_babel.squeeze()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fundamental takeaway message is that the predicted resale prices is the same for the normalized and unnormalized data. So regarding model performance, normalization does not affect the results here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "For basic Linear Regression -- that is, without regularization -- normalization does not affect model performance. Here, whether to normalize the data or not is a question regarding the interpretation of the learned coefficients $\\theta_i$. Without normalization, $\\theta_i$ directly indicate the effect of feature $i$ in the estimate. On the other hand, normalization allows to compare the different $\\theta$ values of the same model. For example, $\\theta_i > \\theta_j$ indicates that feature $i$ is a more important feature/predictor that feature $j$.\n",
    "\n",
    "Once we include regularization, normalizing the data is usually recommended. Recall that the regularization term we introduced in the lecture (there are many alternatives) calculated\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^d \\theta_{i}^2\n",
    "$$\n",
    "\n",
    "Without normalizing the data, the magnitudes of the $\\theta_i$ can be very different (see the example above), which means that the regularization term would \"punish\" the $\\theta_i$ differently. Normalizing the data will bring the magnitudes of the $\\theta_i$ into the same range, enabling a fair regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
