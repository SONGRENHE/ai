{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787356d6",
   "metadata": {},
   "source": [
    "# CS5228 Assignment 2b - Linear Models & Model Selection (50 Points)\n",
    "\n",
    "Hello everyone, this assignment notebook covers Linear Models & Model Selection (i.e., hyperparameter tuning). There are some code-completion tasks and question-answering tasks in this answer sheet. For code completion tasks, please write down your answer (i.e., your lines of code) between sentences that \"Your code starts here\" and \"Your code ends here\". The space between these two lines does not reflect the required or expected lines of code. For answers in plain text, you can refer to [this Markdown guide](https://medium.com/analytics-vidhya/the-ultimate-markdown-guide-for-jupyter-notebook-d5e5abf728fd) to customize the layout (although it shouldn't be needed).\n",
    "\n",
    "When you work on this notebook, you can insert additional code cells (e.g., for testing) or markdown cells (e.g., to keep track of your thoughts). However, before the submission, please remove all those additional cells again. Thanks!\n",
    "\n",
    "**Important:** \n",
    "* Remember to rename and save this Jupyter notebook as **A2b_YourName_YourNUSNETID.ipynb** (e.g., **A2b_BobSmith_e12345678.ipynb**) before submission! Failure to do so will yield a penalty of 1 Point.\n",
    "* Remember to rename and save the script file **A2b_script.py** as **A2b_YourName_YourNUSNETID.py** (e.g., **A2b_BobSmith_e12345678.py**) before submission! Failure to do so will yield a penalty of 1 Point.\n",
    "* Submission deadline is Oct 9, 11.59 pm (together with A2a). Late submissions will be penalized by 10% for each additional day.\n",
    "\n",
    "Please also add your nusnet and student id in the code cell below. This is just to make any identification of your notebook doubly sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c1d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_id = ''\n",
    "nusnet_id = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4237ac",
   "metadata": {},
   "source": [
    "Here is an overview over the tasks to be solved and the points associated with each task. The notebook can appear very long and verbose, but note that a lot of parts are there to provide additional explanations, documentation, or some discussion. The code and markdown cells you are supposed to complete are well marked, but you can use the overview below to double-check that you covered everything.\n",
    "\n",
    "* **1 Linear & Logistic Regression (30 Points)**\n",
    "    * 1.1 Implementing Logistic Regression Classifier (14 Points)\n",
    "        * 1.1 a) Calculating the Gradient (4 Points)\n",
    "        * 1.1 b) Implementing Gradient Descent (4 Points)\n",
    "        * 1.1 c) Predicting Labels (2 Points)\n",
    "        * 1.1 d) Hyperparameter Tuning \"By Hand\" and Interpretation of Results (4 Points)\n",
    "    * 1.2 Questions about Linear and Logistic Regression (16 Points)\n",
    "        * 1.2 a) True/False Questions about `MyLogisticRegression` (8 Points)\n",
    "        * 1.2 b) True/False Questions about Linear Regression (8 Points)\n",
    "* **Model Selection (20 Points)**\n",
    "    * 2.1 Data Preprocessing (4 Points)\n",
    "    * 2.2 Performing K-Fold Cross-Validation \"By Hand\" (10 Points)\n",
    "        * 2.1 a) Implement k-fold Cross Validation (4 Points)\n",
    "        * 2.1 b) Run k-fold Cross Validation for 4 Regressors and Discuss the Results. (6 Points)¶\n",
    "    * 2.3 Hyperparameter Tuning (6 Points)\n",
    "        * 2.2 a) Perform hyperparameter tuning for AdaBoost (using Decision Trees)! (3 Points)\n",
    "        * 2.2 b) Discuss your process of finding the best hyperparameter values and the results (3 Points)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410ebfdc",
   "metadata": {},
   "source": [
    "## Setting up the Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736688e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d2b7b5",
   "metadata": {},
   "source": [
    "Making all the required imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3b9e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, f1_score\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from src.utils import plot_validation_results, plot_scores\n",
    "\n",
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce7f4ae",
   "metadata": {},
   "source": [
    "**Important:** This notebook also requires you to complete in a separate `.py` script file. This keeps this notebook cleaner and simplifies testing your implementations for us. As you need to rename the file `A2b_script.py`, you also need to edit the import statement below accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8438e307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from A2b_script import MyLogisticRegression\n",
    "#from A2b_BobSmith_e12345678 import MyLogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fe3e2d",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a7c4b",
   "metadata": {},
   "source": [
    "## 1 Linear & Logistic Regression (30 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9476e9",
   "metadata": {},
   "source": [
    "**Prepare Dataset (nothing for you to do here).** We use the [Banknote Authentication Dataset](https://archive.ics.uci.edu/ml/datasets/banknote+authentication). It contains 1,371 samples, each with 4 numerical features (variance, skewness, kurtosis, and entropy of an image) to predict whether a bank note is genuine or a forgery. We use this dataset mainly for convenience. It basically does not require any data preprocessing as all features are numerical, and there are no \"dirty\" records. There is also no need for normalization/standardization as all features values are about the same range.\n",
    "\n",
    "First, let's load the dataset into a pandas dataframe and have a quick look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa4b933",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bank = pd.read_csv('data/a2-banknote-authentication.csv')\n",
    "\n",
    "df_bank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb845b4",
   "metadata": {},
   "source": [
    "For further processing, we convert the data into numpy arrays; pandas provides convenient methods for that. We also split the data into the input features and the target variable, with the latter being the last column in our data matrix. Lastly, we use `train_test_split` from scitkit-learn to split our dataset into the training and test data. We set the `random_state` to ensure consistent results throughout this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60fa1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert pandas dataframe into numpy array\n",
    "data = df_bank.to_numpy()\n",
    "\n",
    "# Separate input features from target variable\n",
    "X_bank = data[:,:-1]\n",
    "y_bank = data[:,-1].astype(int)\n",
    "\n",
    "# Split into training and test set; we use a common 80/20 split here\n",
    "X_bank_train, X_bank_test, y_bank_train, y_bank_test = train_test_split(X_bank, y_bank, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16997b6f",
   "metadata": {},
   "source": [
    "**Visualization (nothing for you to do here).** It never hurts to first have a quick look a the data. Since we have 4 input features, plotting the data points based on all features is not really possible. What we can do however, since we only have 4 features, we can generate the plots for all *pairs* of features. The code cell below does this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace2ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_0 = np.where(y_bank==0)\n",
    "indices_1 = np.where(y_bank==1)\n",
    "\n",
    "features = ['Variance', 'Skewness', 'Kurtosis', 'Entropy']\n",
    "\n",
    "for feautre_1 in range(X_bank.shape[1]):\n",
    "    for feature_2 in range(feautre_1+1, X_bank.shape[1]):\n",
    "        plt.figure()\n",
    "        plt.scatter(X_bank[:,feautre_1][indices_0], X_bank[:,feature_2][indices_0], c='blue')\n",
    "        plt.scatter(X_bank[:,feautre_1][indices_1], X_bank[:,feature_2][indices_1], c='red')\n",
    "        plt.xlabel(features[feautre_1], fontsize=16)\n",
    "        plt.ylabel(features[feature_2], fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292fe111",
   "metadata": {},
   "source": [
    "From the plots we can see that some of the input features seem to be quite helpful in separating the two classes. For example, if we would only use Variance and Skewness (first plot), we could probably get out a decent classifier. In contrast, considering only Kurtosis and Entropy (last plot), we see only a very poor separation of the class labels, so we would not be able to train a good classifier. Summing up, since already some subsets of features seem to be quite useful, we can expect that considering all features will potentially yield very good results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574508b5",
   "metadata": {},
   "source": [
    "**Training an off-the-shelf Logistic Regression model (nothing for you to do here).** Before you will implement and test your own Logistic Regression classifier, let's first use [`sklearn.linear_model.LogisticRegression`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). This will give us a first idea what accuracy result we can aim for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1dfea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression model over training data\n",
    "sk_logreg = LogisticRegression().fit(X_bank_train, y_bank_train)\n",
    "\n",
    "# Predict labels for test data\n",
    "y_bank_sk_pred = sk_logreg.predict(X_bank_test)\n",
    "\n",
    "# Print results (i.e., comparing predicted labels with groundtruth labels of test data)\n",
    "print('f1 score (test): {:.3f}'.format(f1_score(y_bank_sk_pred, y_bank_test)))\n",
    "\n",
    "# Show number of iterations (for a later comparison)\n",
    "print('Number of iterations: {}'.format(sk_logreg.n_iter_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cd5cd7",
   "metadata": {},
   "source": [
    "The result indeed confirm that we can expect to get very good results with our own implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103653b2",
   "metadata": {},
   "source": [
    "### 1.1 Implementing Logistic Regression (Binary Classification) (14 Points)\n",
    "\n",
    "Your task here is to implement a Logistic Regression Classifier for binary classification. One learning outcome is actually to show how quick and easy this is. Below you can find the skeleton code for the class implementing the Logistic Regression Classifier. You will need to complete this code step by step along with the subtasks 2.1 a-c). \n",
    "\n",
    "We give you two basic methods for free so you can focus on the core parts:\n",
    "\n",
    "* `add_bias()` adds the constant feature value $x_0 = 1$ for each data sample to implement the \"bias trick\"\n",
    "* `calc_closs()` computes the Cross Entropy loss for the binary case, i.e., directly implementing the formula below\n",
    "\n",
    "$$ L = -\\frac{1}{n} \\sum_{i=1}^n \\left[ y_i\\log{\\hat{y}_i} + (1-y_i)\\log{(1- \\hat{y}_i} )\\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fca3b62",
   "metadata": {},
   "source": [
    "#### 1.1 a) Calculating the Gradient (4 Points)\n",
    "\n",
    "Given the non-linear nature of the loss function for the Logistic Regression, we cannot find the best $\\theta$ values that minimize the loss function analytically. Hence, we have to implement it using Gradient Descent. Here, instead of calculating the $\\nabla_\\theta L$, setting it to 0, and solving for $\\theta$, we start with initial parameter values for $\\theta$, calculate the respective gradient, and update $\\theta$ to reduce the loss $L$ iteratively.\n",
    "\n",
    "The gradient for loss $L$ w.r.t. to $\\theta$ is given as:\n",
    "\n",
    "$$\\nabla_\\theta L = \\frac{2}{n} X^T(h_\\theta(X) - y)\\ \\text{, with }\\ h_\\theta(x_i) = \\frac{1}{1+ e^{-\\theta^{T}x_i}}$$\n",
    "\n",
    "\n",
    "**Implement the methods `calc_h()` and `calc_gradient()` to calculate the gradient!** The only reason for doing this using 2 methods is that it allows us to re-use some code later on.\n",
    "\n",
    "You can use the code cell below to check your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a08cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "my_logreg = MyLogisticRegression()\n",
    "\n",
    "# Implement bias trick by adding x0 to all data samples\n",
    "X_bank_train_with_bias = my_logreg.add_bias(X_bank_train)\n",
    "\n",
    "# Initialize theta with random values\n",
    "my_logreg.theta = np.random.rand(X_bank_train_with_bias.shape[1],1)\n",
    "\n",
    "# Calculate the output of h(x)\n",
    "h = my_logreg.calc_h(X_bank_train_with_bias)\n",
    "\n",
    "# Calculate the gradient\n",
    "grad = my_logreg.calc_gradient(X_bank_train_with_bias, y_bank_train, h)\n",
    "\n",
    "print('theta values =\\n{}\\n\\nGradient =\\n{}\\n'.format(my_logreg.theta, grad))\n",
    "\n",
    "print('theta.shape = {} \\t grad.shape = {}'.format(my_logreg.theta.shape, grad.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb619b6",
   "metadata": {},
   "source": [
    "The code call above should result in the following output:\n",
    "    \n",
    "```\n",
    "theta values =\n",
    "[[4.170e-01]\n",
    " [7.203e-01]\n",
    " [1.144e-04]\n",
    " [3.023e-01]\n",
    " [1.468e-01]]\n",
    "\n",
    "Gradient =\n",
    "[[-0.713 -0.713 -0.713 ... -0.713  1.287  1.287]\n",
    " [ 0.979  0.979  0.979 ...  0.979  1.818  1.818]\n",
    " [-2.424 -2.424 -2.424 ... -2.424  1.334  1.334]\n",
    " [-0.07  -0.07  -0.07  ... -0.07   2.702  2.702]\n",
    " [ 1.603  1.603  1.603 ...  1.603 -0.745 -0.745]]\n",
    "\n",
    "theta.shape = (5, 1) \t grad.shape = (5, 1097)\n",
    "```\n",
    "\n",
    "Since we have 4 features an 1 bias, we have 5 theta values, and 5 gradient values for each of the 1,096 training data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b1a60c",
   "metadata": {},
   "source": [
    "#### 1.1 b) Implementing Gradient Descent (4 Points)\n",
    "\n",
    "We now have everything in place to implement the training loop for Gradient Descent.\n",
    "\n",
    "**Implement the method `fit()` to find the best $\\theta$ using Gradient Descent!** Most of the code is given, so you can focus on the loop that performs Gradient Descent -- which is essentially utilizing the methods you have implemented in 1 a). You can test your implementation using the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8670ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "my_logreg = MyLogisticRegression().fit(X_bank_train, y_bank_train, lr=0.001, num_iter=100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac943241",
   "metadata": {},
   "source": [
    "For the default hyperparameter values (`lr=0.01` and `num_iter=100`), the loss should go down to around 1.7."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5157ba78",
   "metadata": {},
   "source": [
    "#### 1.1 c) Predicting Labels (2 Points)\n",
    "\n",
    "Now that you can train your Logistic Regression classifier, you only need to implement the prediction of class labels for unseen data samples.\n",
    "\n",
    "**Implement the method predict()** to predict the class label (0 or 1) for an array of unseen data samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525dc412",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "# Default values for 1.1 c)\n",
    "lr = 0.001\n",
    "num_iter = 100\n",
    "\n",
    "# Your values you found for 1.1 d)\n",
    "#lr = ...\n",
    "#num_iter = ...\n",
    "\n",
    "\n",
    "my_logreg = MyLogisticRegression().fit(X_bank_train, y_bank_train, lr=lr, num_iter=num_iter, verbose=True)\n",
    "\n",
    "y_bank_my_pred = my_logreg.predict(X_bank_test)\n",
    "\n",
    "y_bank_my_pred_train = my_logreg.predict(X_bank_train)\n",
    "y_bank_my_pred_test = my_logreg.predict(X_bank_test)\n",
    "\n",
    "f1_bank_train = f1_score(y_bank_train, y_bank_my_pred_train)\n",
    "f1_bank_test = f1_score(y_bank_test, y_bank_my_pred_test)\n",
    "\n",
    "print('f1 score (training): {:.3f}'.format(f1_bank_train))\n",
    "print('f1 score (test): {:.3f}'.format(f1_bank_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf82d01c",
   "metadata": {},
   "source": [
    "For the default hyperparameter values (`lr=0.001` and `num_iter=100`), you should see f1 scores like below:\n",
    "\n",
    "```\n",
    "f1 score (training): 0.382\n",
    "f1 score (test): 0.412\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92b2e59",
   "metadata": {},
   "source": [
    "#### 1.1 d) Hyperparameter Tuning \"By Hand\" and Interpretation of Results (3 Points)\n",
    "\n",
    "Seeing the loss going down (with the example parameter values above) is a good start. However, an f1 score over the test data if around 0.4 is not that great. In fact, we are worse than a random guesser. We also already know from using `sklearn` that an f1 score of over 0.98 is possible. Of course, we could simply increase the value of `num_iter` more and more, knowing that at some point Gradient Descent will eventually reach the minimum. But this would  unnecessarily increase the computation time.\n",
    "\n",
    "**Try different values for `lr` and `num_iter` and briefly discuss your observations!** You can simply use the code cell above for playing around with both parameters. In more detail:\n",
    "\n",
    "* Find a setting for both parameters that will increase the f1 score over the test data to at least 0.98; while keeping `num_iter` as small as possible. (Hint: You don't have to make fine-grained changes to the parameters. For example, there's no need in decreasing `num_iter` from 100 to 99 :). Overall, this should be very quick and easy to do. Just try some parameter combination and see how it behaves.\n",
    "\n",
    "* Discuss any interesting observations you have made while finding such a parameter setting (e.g., how the development of the loss behaves, limitations on the choice of parameter values, etc.) together with a brief explanation. You might also want to compare the results/observations with the `sklearn` run above, as well as with the example we used in the lecture.\n",
    "\n",
    "**Your Answer**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2b7fef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1aa5def",
   "metadata": {},
   "source": [
    "### 1.2 Questions about Linear and Logistic Regression (16 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5214b6",
   "metadata": {},
   "source": [
    "**1.2 a) True/False Questions about `MyLogisticRegression` (8 Points)**: In the table below are 8 statements that are either True or False. Complete the table to specify whether a statement is True or False, and provide a brief explanation for your answer (Your explanation is more important than a simple True/False answer)\n",
    "\n",
    "**Your Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bffc67",
   "metadata": {},
   "source": [
    "This is a markdown cell. Please fill in your answers for (1)~(8).\n",
    "\n",
    "| No. | Statement                                                                                                   | True or False?       | Brief Explanation |\n",
    "|-----|------------------------------------------------------------------------------------------------------------|--------------| ------- |\n",
    "| (1)  | To make `MyLogisticRegression` support Polynomial Logistic Regression, we only need to change the method `calc_h()` and `calc_gradient()` | True/False |     |\n",
    "| (2)  | If the dataset is linearly separable, `MyLogisticRegression` will eventually achieve a loss of 0 | True/False|   |\n",
    "| (3)  | Not matter how $\\theta$ is initialized, `MyLogisticRegression` will eventually always converge to the same solution (for the same dataset) | True/False |   |\n",
    "| (4)  | Since `MyLogisticRegression` considers the interaction between features, it always performs better then a (single) Decision Tree | True/False |    |\n",
    "| (5)  | Without any extensions, `MyLogisticRegression` is of no use for classification tasks with more than 2 classes | True/False |    |\n",
    "| (6)  | If we would extend `MyLogisticRegression` to support *Mini-Batch Gradient Descent*, we should generally use lower learning rates when training a model | True/False |    |\n",
    "| (7)  | If you would extend `MyLogisticRegression` to support Regularization, you would see larger training loss | True/False |    |\n",
    "| (8)  | If you would have forgotten the constant factor of 2 in `calc_gradient()` your implementation would have converged to a different optimum | True/False |     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b295710",
   "metadata": {},
   "source": [
    "**1.2 b) True/False Questions about Linear Regression (8 Points)**: In the table below are 8 statements that are either True or False. Complete the table to specify whether a statement is True or False, and provide a brief explanation for your answer (Your explanation is more important than a simple True/False answer)\n",
    "\n",
    "**Your Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2721e67c",
   "metadata": {},
   "source": [
    "This is a markdown cell. Please fill in your answers for (1)~(8).\n",
    "\n",
    "\n",
    "| No. | Statement                                                                                                   | True or False?       | Brief Explanation |\n",
    "|-----|------------------------------------------------------------------------------------------------------------|--------------| ------- |\n",
    "| (1)  | Linear Regression is very sensitive to outliers | True/False |     |\n",
    "| (2)  | Training a Linear Regression Model requires the data to indeed show a linear relationship | True/False |    |\n",
    "| (3)  | Assume 2 $d$-dimensional datasets $D_1$ and $D_2$ with $N$ data points. If after training a Linear Regression model over $D_1$ and $D_2$ yields very similar $\\theta$ values, then $D_1$ and $D_2$ must also be very similar| True/False |     |\n",
    "| (4)  | For loss to be 0, all $\\theta$ values must be 0 (i.e., $\\theta_0 = 0$, $\\theta_1 = 0$, ...$\\theta_{d+1} = 0$)  so that $h_\\theta(x) = 0$ | True/False |     | \n",
    "| (5)  | It's always better to solve a Linear Regression task analytically using the *Normal Equation* and not using Gradient as it yields the best $\\theta$ values without the need for convergence | True/False |      |\n",
    "| (6)  | Feature scaling (e.g., z-score standardization) speeds up the convergence of Gradient Descent | True/False |      |\n",
    "| (7)  | Linear Regression (not Polynomial Linear Regression) is such a simple model that overfitting cannot occur | True/False |      |\n",
    "| (8)  | It is possible for a dataset containing samples with a lot of noise to get loss of 0. | True/False |     |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31919f06",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c534ec5d",
   "metadata": {},
   "source": [
    "## 2 Model Selection (20 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a0a45a",
   "metadata": {},
   "source": [
    "The topic \"Classification & Regression\" covered a whole series of different models. In this section, we look at the basic data mining task of finding the best model for a given dataset: which model performs best with which hyperparameters. To keep it simple and keep the implementation work to a minimum, we make full use of scikit-learn (see additional hints in the subtasks)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027fb89a",
   "metadata": {},
   "source": [
    "#### Prepare Dataset\n",
    "\n",
    "#### Load Dataset from File\n",
    "\n",
    "We use a [WHO Life Expectancy](https://www.kaggle.com/kumarajarshi/life-expectancy-who) dataset for this task. Note that we cleaned the dataset for you (i.e., there are no dirty records in there)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21502084",
   "metadata": {},
   "source": [
    "Let's load the file and have a look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/a2-life-expectancy-cleaned.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bd7199",
   "metadata": {},
   "source": [
    "For your convenience, we split the dataframe into two, one containing the input features, the other containing the class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a66625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = df.iloc[:,0:-1]\n",
    "df_y = df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2365f5",
   "metadata": {},
   "source": [
    "## 2.1 Data Preprocessing (4 Points)\n",
    "\n",
    "As usual, the first step is data preprocessing (informed by an EDA). As mentioned, above there's not much to do as this dataset does not contain any \"dirty\" records, particularly, there are no NA values in any of the columns/features. As such, there should be no need to remove any samples.\n",
    "\n",
    "**Perform and data preprocessing/transformation steps you deem appropriate!** As it might affect your decision, the data will be used to train to train 6 different regression model (you can have a quick peak below to see which 6 models are used). Note that some preprocessing steps might be easier to perform on the pandas dataframe while others on the NumPy arrays. This is why we provide 2 code cell, but it's up to which one to use. We also already imported [`sklearn.preprocessing`](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
    "\n",
    "**Note:** Perform only preprocessing steps that you indeed deem mandatory and/or meaningful, and briefly(!) explain you decision by commenting your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8cba23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "### Your code starts here ###############################################################\n",
    "\n",
    "\n",
    "\n",
    "### Your code ends here #################################################################\n",
    "#########################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe8fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dataframes to numpy arrays\n",
    "X, y = df_X.to_numpy(), df_y.to_numpy()\n",
    "\n",
    "# Split dataset in training and test data (20% test data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6cd73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################\n",
    "### Your code starts here ###############################################################\n",
    "\n",
    "\n",
    "\n",
    "### Your code ends here #################################################################\n",
    "#########################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd4864",
   "metadata": {},
   "source": [
    "#### Training and Evaluating off-the-shell Models\n",
    "\n",
    "Packages like `scikit-learn` make it almost trivial to train a variety of models with a minimum number of lines of codes. In the following code cell, we train 6 different models with their default values using the training data, and evaluate them over the test set. We use the F1 score as the evaluation metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85326c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('RSME scores for test data for all regressors')\n",
    "print('============================================')\n",
    "for model in [KNeighborsRegressor(), LinearRegression(), DecisionTreeRegressor(),\n",
    "              AdaBoostRegressor(), RandomForestRegressor(), GradientBoostingRegressor()]:    \n",
    "    try:\n",
    "        regressor = model.fit(X_train, y_train)\n",
    "        # Predict values for test samples\n",
    "        y_pred = model.predict(X_test)\n",
    "        # Calculate the RSME\n",
    "        rsme = mean_squared_error(y_test, y_pred, squared=False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        # Handle exception (e.g., a regressor is still None)\n",
    "        rsme = '---'\n",
    "    # Print regressor name and the RSME score\n",
    "    print('{}:\\t{:.3}'.format(type(regressor).__name__, rsme))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c5aa14",
   "metadata": {},
   "source": [
    "### 2.2 Performing K-Fold Cross-Validation \"By Hand\" (8 Points)\n",
    "\n",
    "The code below shows the basic loop for an evaluation using k-fold cross-validation. The only bits missing are the steps to (a) create the k folds and (b) to construct the training set of (k-1) folds and the validation set of 1 fold. For this task, use the `DecisionTreeRegressor` by default as it is the fastest to evaluate. \n",
    "\n",
    "#### 2.2 a) Implement k-fold Cross Validation (4 Points)\n",
    "For testing and debugging, feel free to reduce `num_folds` (e.g., 5) and `param_choices` (e.g., `[1, 2, 3]`) in the beginning. (Hint: Have a look at [`np.array_split`](https://numpy.org/doc/stable/reference/generated/numpy.array_split.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "num_folds = 5 # For testing debugging\n",
    "#num_folds = 10\n",
    "\n",
    "param_choices = [1, 2, 3, 5] # For testing debugging\n",
    "#param_choices = [1, 2, 3, 5, 8, 10, 12, 15, 20, 25, 50]\n",
    "\n",
    "\n",
    "\n",
    "X_train_folds = []\n",
    "y_train_folds = []\n",
    "\n",
    "#########################################################################################\n",
    "### Your code starts here ###############################################################\n",
    "\n",
    "\n",
    "\n",
    "### Your code ends here #################################################################\n",
    "#########################################################################################\n",
    "\n",
    "\n",
    "param_to_scores = {}\n",
    "\n",
    "for param in param_choices:\n",
    "    \n",
    "    ## We want to keep track of the training scores and validation scores\n",
    "    rsme_train, rsme_valid = [], []\n",
    "    \n",
    "    for i in range(num_folds):\n",
    "        X_train_fold, X_valid_fold = None, None\n",
    "        y_train_fold, y_valid_fold = None, None\n",
    "\n",
    "        #########################################################################################\n",
    "        ### Your code starts here ###############################################################\n",
    "        \n",
    "\n",
    "        \n",
    "        ### Your code ends here #################################################################\n",
    "        #########################################################################################           \n",
    "\n",
    "        \n",
    "        ## Train all the classifiers one-by-one and discuss the results\n",
    "        #regressor = KNeighborsRegressor(n_neighbors=param).fit(X_train_fold, y_train_fold)\n",
    "        regressor = DecisionTreeRegressor(max_depth=param).fit(X_train_fold, y_train_fold)\n",
    "        #regressor = RandomForestRegressor(max_depth=param).fit(X_train_fold, y_train_fold)\n",
    "        #regressor = GradientBoostingRegressor(max_depth=param).fit(X_train_fold, y_train_fold)\n",
    "\n",
    "        \n",
    "        ## Predict labels for for training validation set\n",
    "        y_pred_fold_train = regressor.predict(X_train_fold)\n",
    "        y_pred_fold_valid = regressor.predict(X_valid_fold)\n",
    "      \n",
    "        ## Keep track of training and validation scores\n",
    "        rsme_train.append(mean_squared_error(y_train_fold, y_pred_fold_train, squared=False))\n",
    "        rsme_valid.append(mean_squared_error(y_valid_fold, y_pred_fold_valid, squared=False))\n",
    "        \n",
    "    ## Keep track of all num_folds f1 scores for current param (for plotting)\n",
    "    param_to_scores[param] = (rsme_train, rsme_valid)\n",
    "    \n",
    "    ## Print statement for some immediate feedback\n",
    "    print('param = {}, RSME (training) = {:.3f}, RSME (validation) = {:.3f} (stdev: {:.3f})'.format(param, np.mean(rsme_train), np.mean(rsme_valid), np.std(rsme_valid)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5659c3a6",
   "metadata": {},
   "source": [
    "#### Visualization of Results\n",
    "\n",
    "We provide you with 2 methods to visualize the results. `plot_validation_results()` shows all `num_folds` scores for each parameter setting together with the means and standard deviations of the validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c8937",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_validation_results(param_to_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011241f5",
   "metadata": {},
   "source": [
    "The method `plot_scores()` shows the training and validation scores for each parameter setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad0e428",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scores(param_to_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec9f44c",
   "metadata": {},
   "source": [
    "The code above for the k-fold cross-validation already contains the lines for the training of 4 different regressors:\n",
    "\n",
    "* [`KNeighborsRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html) with `n_neighbors` as hyperparameter\n",
    "\n",
    "* [`DecisionTreeRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html) with `max_depth` as hyperparameter\n",
    "\n",
    "* [`RandomForestRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html) with `max_depth` as hyperparameter\n",
    "\n",
    "* [`GradientBoostingRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html) with `max_depth` as hyperparameter\n",
    "\n",
    "We focus on these 4 models since we look at only one hyperparameter and consider only integer values. This `n_neighbors` (for KNN) and `max_depth` for the tree-based models are important hyperparameters assume integer values.\n",
    "\n",
    "\n",
    "#### 2.2 b) Run k-fold Cross Validation for 4 Regressors and Discuss the Results. (6 Points)¶\n",
    "\n",
    "You should see quite a number of differences regarding runtimes, issues of overfitting and underfitting, overall performance, etc. Hint: Use the methods `plot_scores()` and `plot_validation_results` to visualize the results; save the 2 plots for each regressor as images so you can easily compare them side by side (there's no need to submit the images later!)\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd6055",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d30c6ad",
   "metadata": {},
   "source": [
    "### 2.3 Hyperparameter Tuning (6 Points)\n",
    "\n",
    "The results of the different models in off-the-shelf implementations vary quite a bit, but of course, we used the only default parameters of each implementation which might or might not be good for our dataset and task. In practice, you would perform hyperparameter tuning for all or at least most models. However, this is unnecessarily since the tuning process is very similar for each model. So we do it only for one model: **AdaBoost** (which shows a comparatively poor performance with the default values)\n",
    "\n",
    "#### 2.3 a) Perform hyperparameter tuning for AdaBoost (using Decision Trees)! (3 Points)\n",
    "\n",
    "**Important hints:**\n",
    "\n",
    "* Use [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)! It automatically performs k-fold cross-validation (by default: k=5, which is fine) for all specified combinations of hyperparameter values. With [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html), finding the best model (i.e., the model with the best hyperparameter models) should only require only very few lines of code!\n",
    "* As we have 10 classes we rely on averaged f1 scores. Please use `scoring='f1_macro'` for [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)!\n",
    "* [`AdaBoostRegressor`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html) with (`base_estimator=DecisionTreeRegressor()`) provides a whole range of hyperparameters. Pick a **3-4 meaningful hyperparameters** to tune the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01e2c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model = None\n",
    "\n",
    "base_estimator = DecisionTreeRegressor()\n",
    "\n",
    "#########################################################################################\n",
    "### Your code starts here ###############################################################\n",
    "\n",
    "\n",
    "\n",
    "### Your code ends here #################################################################\n",
    "######################################################################################### \n",
    "\n",
    "# Store the parameters of the best model\n",
    "best_params = model.best_params_\n",
    "\n",
    "# Predict class labels of test data on the model with the best found parameters\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the f1 score\n",
    "best_f1 = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "print('Best AdaBoost (with Decision Tree) regressor: {} (RSME: {:.3f})'.format(best_params, best_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80e4797",
   "metadata": {},
   "source": [
    "#### 2.3 b) Discuss your process of finding the best hyperparameter values and the results (3 Points). \n",
    "\n",
    "Interesting points may include the choice of values for the grid search (and required changes), the improvements compared to the results for the default parameters in 3.1 a), the overall time required to find the best hyperparameter values, or any other interesting or surprising observations you have made during this task.\n",
    "\n",
    "**Your answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c6e2bf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c79688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
