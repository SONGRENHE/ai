{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 6 - Classification & Regression II (Tree Ensembles)\n",
    "\n",
    "The goals of this notebook is to go trough the most popular ensemble methods for Decision Trees. Compared to the previous notebook that look at individual Decision Trees, visualizing the results (i.e., the trees) is no longer meaningfully possible. Hence we focus on the results (f1 scores) for different hyperparameter settings.\n",
    "\n",
    "Let's get started...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the notebook\n",
    "\n",
    "Specify how plots get rendered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make all required imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training & Test\n",
    "\n",
    "We already have done these steps many time. so there's no need for any details. As Decision Trees do not require normalized data, there's also not much to do in terms of data preprocessing.\n",
    "\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/cardio_train.csv', sep=';')\n",
    "\n",
    "# Drop \"artificial\" feature id\n",
    "df.drop(columns=['id'], inplace=True)\n",
    "\n",
    "# Show the first 5 columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to numpy arrays\n",
    "X = df[['age', 'gender', 'height', 'weight', 'ap_hi', 'ap_lo', 'cholesterol', 'gluc', 'smoke', 'alco', 'active']].to_numpy()\n",
    "y = df[['cardio']].to_numpy().squeeze()\n",
    "\n",
    "# Split dataset in to training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Size of training set: {}\".format(len(X_train)))\n",
    "print(\"Size of test: {}\".format(len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Decision Tree Classifier\n",
    "\n",
    "For comparison, we train an individual Decision tree for different values of `max_depth`; same as in the previous notebook just with different data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_depth = 20\n",
    "\n",
    "# Keep track of depth and f1 scores for plotting\n",
    "ds, f1s = [], []\n",
    "\n",
    "# Loop over all values for max_depth\n",
    "for d in range(1, max_depth+1):\n",
    "    ds.append(d)\n",
    "    # Train Decision Tree classifier for current value of max_depth\n",
    "    clf = DecisionTreeClassifier(max_depth=d, criterion='gini', random_state=10).fit(X_train, y_train)\n",
    "    # Predict class labels for test set\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # Calculate f1 score between predictions and ground truth\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    f1s.append(f1)\n",
    "    \n",
    "print('A maximum depth of {} yields the best f1 score of {:.3f}'.format(ds[np.argmax(f1s)], np.max(f1s), ))        \n",
    "    \n",
    "# Plot the results (max_depth vs. f1.score)\n",
    "plt.figure()\n",
    "plt.plot(ds, f1s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Classifier\n",
    "\n",
    "We introduced Bagging as simple ways to train multiple models on different datasets, where each dataset is a random sample (with replacement) of the original dataset of the same size. scikit-learn's [BaggingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) implements this idea. As Bagging is a General concept and not limited to Decision Trees, `BaggingClassifier` gets as input a `base_estimator` which is a Decision Tree in our case.\n",
    "\n",
    "Note that we now have 2 parameters: \n",
    " * `max_depth` of Decision Tree base estimator\n",
    " * `n_estimators` as the number of models\n",
    "\n",
    "(well, there are more parameters but we just focus on these 2 here)\n",
    "\n",
    "Since you have not 2 parameters to tune, we can implement this as nested loop to go over all combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_depth = 20\n",
    "\n",
    "ds, ns, f1s = [], [], []\n",
    "\n",
    "# Loop over all values for max_depth\n",
    "for d in range(1, max_depth+1):\n",
    "    for n in [10, 25, 50, 100]:\n",
    "        ds.append(d)\n",
    "        ns.append(n)\n",
    "        \n",
    "        # Train Decision Tree classifier for current value of max_depth\n",
    "        base_estimator = DecisionTreeClassifier(max_depth=d, random_state=10)\n",
    "\n",
    "        clf = BaggingClassifier(base_estimator=base_estimator, n_estimators=n, max_features=1.0).fit(X_train, y_train)\n",
    "        # Predict class labels for test set\n",
    "        y_pred = clf.predict(X_test)\n",
    "        # Calculate f1 score between predictions and ground truth\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1s.append(f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the result, i.e., the f1 scores for each parameter combination using a 3d plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel(r'max_depth', fontsize=16)\n",
    "ax.set_ylabel(r'n_estimators', fontsize=16)\n",
    "ax.set_zlabel('f1 score', fontsize=16)\n",
    "\n",
    "surf = ax.plot_trisurf(ds, ns, f1s, cmap=plt.cm.coolwarm, linewidth=0, antialiased=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract the best f1 score and the parameter combination that resulted in the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_max = np.max(f1s)\n",
    "\n",
    "print('The hights f1 score across all runs: {:.3f}'.format(f1_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_runs = np.where(f1s == f1_max)[0]\n",
    "\n",
    "print('The following runs resulted in the hightest f1 score of {:.3f}'.format(f1_max))\n",
    "for run in best_runs:\n",
    "    print('* max_depth = {}, n_estimators = {}'.format(ds[run], ns[run]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "A [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) goes further then Bagging in such a way that each dataset is not only sample with respect to the data items but also with respect to the features. The code for the evaluation -- considering that we again only look at the 2 parameters `max_depth` and `n_estimators` -- is essentially the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_depth = 20\n",
    "\n",
    "ds, ns, f1s = [], [], []\n",
    "\n",
    "# Loop over all values for max_depth\n",
    "for d in range(1, max_depth+1):\n",
    "    for n in [10, 25, 50, 100]:\n",
    "        ds.append(d)\n",
    "        ns.append(n)\n",
    "        # Train Decision Tree classifier for current value of max_depth\n",
    "        clf = RandomForestClassifier(max_depth=d, criterion='gini', n_estimators=n).fit(X_train, y_train)\n",
    "        # Predict class labels for test set\n",
    "        y_pred = clf.predict(X_test)\n",
    "        # Calculate f1 score between predictions and ground truth\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1s.append(f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can plot it scores for different parameter combinations again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel(r'max_depth', fontsize=16)\n",
    "ax.set_ylabel(r'n_estimators', fontsize=16)\n",
    "ax.set_zlabel('f1 score', fontsize=16)\n",
    "\n",
    "surf = ax.plot_trisurf(ds, ns, f1s, cmap=plt.cm.coolwarm, linewidth=0, antialiased=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...as well as extracting the best score and respective parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_max = np.max(f1s)\n",
    "\n",
    "print('The hights f1 score across all runs: {:.3f}'.format(f1_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_runs = np.where(f1s == f1_max)[0]\n",
    "\n",
    "print('The following runs resulted in the hightest f1 score of {:.3f}'.format(f1_max))\n",
    "for run in best_runs:\n",
    "    print('* max_depth = {}, n_estimators = {}'.format(ds[run], ns[run]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost Classifier\n",
    "\n",
    "Similar to Bagging, AdaBoost is a general concept and not limited to Decision Trees. The basic idea of AdaBoost is to train series of classifiers, where the next classifiers tries to correct the errors of the previous one. For this, scikit-learn provides its [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier). Similar to `BaggingClassifier`, we have to specify to use a Decision Tree as `base_estimator`.\n",
    "\n",
    "The code for trying different parameter combinations should look familiar by now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_depth = 10\n",
    "\n",
    "ds, ns, f1s = [], [], []\n",
    "\n",
    "# Loop over all values for max_depth\n",
    "for d in range(1, max_depth+1):\n",
    "    for n in [10, 25, 50, 100]:\n",
    "        ds.append(d)\n",
    "        ns.append(n)\n",
    "        # Train Decision Tree classifier for current value of max_depth\n",
    "        base_estimator = DecisionTreeClassifier(max_depth=d, random_state=100)\n",
    "\n",
    "        clf = AdaBoostClassifier(base_estimator=base_estimator, n_estimators=n).fit(X_train, y_train)\n",
    "        # Predict class labels for test set\n",
    "        y_pred = clf.predict(X_test)\n",
    "        # Calculate f1 score between predictions and ground truth\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel(r'max_depth', fontsize=16)\n",
    "ax.set_ylabel(r'n_estimators', fontsize=16)\n",
    "ax.set_zlabel('f1 score', fontsize=16)\n",
    "\n",
    "surf = ax.plot_trisurf(ds, ns, f1s, cmap=plt.cm.coolwarm, linewidth=0, antialiased=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_max = np.max(f1s)\n",
    "\n",
    "print('The hights f1 score across all runs: {:.3f}'.format(f1_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_runs = np.where(f1s == f1_max)[0]\n",
    "\n",
    "print('The following runs resulted in the hightest f1 score of {:.3f}'.format(f1_max))\n",
    "for run in best_runs:\n",
    "    print('* max_depth = {}, n_estimators = {}'.format(ds[run], ns[run]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier\n",
    "\n",
    "Lastly, we can look at Gradient Boosting using the [GradientBoostingClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html), again here experimenting with different values for `max_depth` and `n_estimators`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_depth = 10\n",
    "\n",
    "ds, ns, f1s = [], [], []\n",
    "\n",
    "# Loop over all values for max_depth\n",
    "for d in range(1, max_depth+1):\n",
    "    for n in [10, 25, 50, 100]:\n",
    "        ds.append(d)\n",
    "        ns.append(n)    \n",
    "        # Train Decision Tree classifier for current value of max_depth\n",
    "        clf = GradientBoostingClassifier(max_depth=d, n_estimators=n).fit(X_train, y_train)\n",
    "        # Predict class labels for test set\n",
    "        y_pred = clf.predict(X_test)\n",
    "        # Calculate f1 score between predictions and ground truth\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        f1s.append(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.set_xlabel(r'max_depth', fontsize=16)\n",
    "ax.set_ylabel(r'n_estimators', fontsize=16)\n",
    "ax.set_zlabel('f1 score', fontsize=16)\n",
    "\n",
    "surf = ax.plot_trisurf(ds, ns, f1s, cmap=plt.cm.coolwarm, linewidth=0, antialiased=False)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_max = np.max(f1s)\n",
    "\n",
    "print('The hights f1 score across all runs: {:.3f}'.format(f1_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_runs = np.where(f1s == f1_max)[0]\n",
    "\n",
    "print('The following runs resulted in the hightest f1 score of {:.4f}'.format(f1_max))\n",
    "for run in best_runs:\n",
    "    print('* max_depth = {}, n_estimators = {}'.format(ds[run], ns[run]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this dataset and with the parameter values given, all classifiers show very comparable results. So (single) Decision Trees are not bad per se :). Of course, tree ensemble method offer additional hyperparameter setting worth tuning. Also, this dataset is not overly large or as a lot of features. All those can help a Decision Tree to keep up with the ensemble methods. \n",
    "\n",
    "We can certainly see that ensemble methods take much more time to evaluate. Firstly, each training takes more time as multiple models are built, and secondly, ensemble methods offer more hyperparameters that potentially can affect the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
